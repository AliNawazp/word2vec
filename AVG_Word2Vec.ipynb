{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39188af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import sqlite3\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2c5cb",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a841138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")\n",
    "data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3 \"\"\", con)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e5fea",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7477608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1\n",
    "data[\"Output\"]=data.Score.map(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d88122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76998c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341af27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data.HelpfulnessNumerator<=data.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61156a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfd510",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9957ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dc83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bdb690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 364171/364171 [06:13<00:00, 974.45it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_text = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data['Text'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_text.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45c95f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 364171/364171 [04:22<00:00, 1387.36it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_summary = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(data['Summary'].values):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    preprocessed_summary.append(sentance.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74cbc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame({\"Text\":preprocessed_text,\"Summart\":preprocessed_summary,\"Output\":data[\"Output\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "277c1499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summart</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>advertised</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summart  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...             advertised   \n",
       "2  confection around centuries light pillowy citr...           delight says   \n",
       "\n",
       "   Output  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09cedab",
   "metadata": {},
   "source": [
    "# AVG_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987267ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 364171/364171 [00:06<00:00, 59505.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 364171/364171 [00:02<00:00, 142830.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#we are converting into the format where gensim.word2vec is understandable\n",
    "text=[]\n",
    "for i in tqdm(preprocessed_text):\n",
    "    text.append(i.split())\n",
    "summary=[]\n",
    "for i in tqdm(preprocessed_summary):\n",
    "    summary.append(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba7fa224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first argument is text you want convert\n",
    "#the format of text should be [[w1,w2,..],[w1,w2,...],...] this is why we created text=[],summary=[] to get into that format\n",
    "#min_count=5 means consider those words that occurs atleast 5 times in corpus\n",
    "#window=10 means it consider 5 words before and after of target word\n",
    "#workers means cores of computer\n",
    "#vector_size=50 means the vector size will be 50 dimensional for each word\n",
    "w2v_model_text = Word2Vec(text,min_count=1,vector_size=50,window=10,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e64c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver', 0.7656199932098389),\n",
       " ('windows', 0.7550932765007019),\n",
       " ('mirror', 0.7455266714096069),\n",
       " ('ceiling', 0.739784300327301),\n",
       " ('wall', 0.7203813195228577),\n",
       " ('pc', 0.713884711265564),\n",
       " ('patio', 0.7099625468254089),\n",
       " ('hook', 0.7069205045700073),\n",
       " ('keyboard', 0.7066042423248291),\n",
       " ('hall', 0.7011048793792725)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_text.wv.most_similar(\"computer\") #this gives similar words and value says how similar it is\n",
    "#from this we can say word2vec consider sematic relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98955706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2126676 , -0.01129488,  1.00491   ,  2.170243  , -1.9453751 ,\n",
       "       -0.04441053,  1.329476  ,  1.7078251 , -1.0448779 , -0.0793432 ,\n",
       "        1.1371223 , -0.4501713 ,  1.4649297 ,  2.7449675 , -1.2288195 ,\n",
       "       -0.997115  ,  0.89129627, -0.9795717 ,  0.77115273,  1.5371093 ,\n",
       "       -0.9909169 ,  1.461338  , -0.20024483, -0.43253207, -0.84365815,\n",
       "       -0.00501731, -0.09819211, -0.90709704, -0.82251865,  0.7382851 ,\n",
       "        0.42454004,  0.2568354 , -0.5872567 , -0.39878687,  0.11796318,\n",
       "       -0.7680922 , -1.492321  , -3.5129592 ,  0.29314142, -2.5419798 ,\n",
       "        0.78526056, -0.6571092 ,  0.14415418, -2.4304802 ,  2.9333928 ,\n",
       "        2.8084698 ,  0.25779676,  0.8923801 , -2.1703744 ,  1.3833836 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this gives to numpy vector size you mentioned in above\n",
    "w2v_model_text.wv[\"computer\"] #wv means wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4e9fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_summary = Word2Vec(summary,min_count=1,vector_size=50,window=10,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b1c9154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 364171/364171 [01:45<00:00, 3450.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 364171/364171 [00:13<00:00, 26996.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "vector_text=[]\n",
    "vector_summary=[]\n",
    "for i in tqdm(text):\n",
    "    vec=np.zeros(50)\n",
    "    n=len(i)\n",
    "    for j in i:\n",
    "        vec=vec+w2v_model_text.wv[j]\n",
    "    vector_text.append(vec/n)\n",
    "for i in tqdm(summary):\n",
    "    vec=np.zeros(50)\n",
    "    n=len(i)\n",
    "    for j in i:\n",
    "        vec=vec+w2v_model_summary.wv[j]\n",
    "    vector_summary.append(vec/n)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c96b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame({\"Text_vector\":vector_text,\"Summary_vector\":vector_summary,\"Output\":df[\"Output\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81164890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_vector</th>\n",
       "      <th>Summary_vector</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.1416406190913657, -0.7423293062526247, -1.0...</td>\n",
       "      <td>[-0.6148168751969934, 0.1694793924689293, -0.3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.2960836895638042, 0.8461025146146616, -0.3...</td>\n",
       "      <td>[-0.5952607989311218, 0.15128670632839203, 0.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.04053393369540572, 0.5774340040516108, 0.4...</td>\n",
       "      <td>[-0.7522922456264496, 0.24452942609786987, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.4054381677673923, 0.1373030828932921, -0.7...</td>\n",
       "      <td>[-0.10200139973312616, -0.041098836809396744, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.15094553321026838, -0.21456006054694837, -...</td>\n",
       "      <td>[0.32099931687116623, 0.4066705498844385, 0.77...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text_vector  \\\n",
       "0  [1.1416406190913657, -0.7423293062526247, -1.0...   \n",
       "1  [-0.2960836895638042, 0.8461025146146616, -0.3...   \n",
       "2  [-0.04053393369540572, 0.5774340040516108, 0.4...   \n",
       "3  [-0.4054381677673923, 0.1373030828932921, -0.7...   \n",
       "4  [-0.15094553321026838, -0.21456006054694837, -...   \n",
       "\n",
       "                                      Summary_vector  Output  \n",
       "0  [-0.6148168751969934, 0.1694793924689293, -0.3...       1  \n",
       "1  [-0.5952607989311218, 0.15128670632839203, 0.6...       0  \n",
       "2  [-0.7522922456264496, 0.24452942609786987, 0.0...       1  \n",
       "3  [-0.10200139973312616, -0.041098836809396744, ...       0  \n",
       "4  [0.32099931687116623, 0.4066705498844385, 0.77...       1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337c9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
